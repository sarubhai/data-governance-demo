services:
  # Dependencies
  broker:
    image: confluentinc/cp-kafka:7.4.0
    container_name: broker
    hostname: broker
    restart: always
    env_file:
      - .env
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: broker
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=broker -Dcom.sun.management.jmxremote.rmi.port=9101
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid" 
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: ${KAFKA_CLUSTER_ID}
    ports:
      - 9092:9092
      - 9101:9101
    volumes:
      - broker_logdir:/var/lib/kafka/data
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 5
      start_period: 60s
      test: nc -z broker 9092
      timeout: 5s

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: schema-registry
    hostname: schema-registry
    restart: always
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: __schemas
    ports:
      - 8081:8081
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 3
      start_period: 60s
      test: nc -z schema-registry 8081
      timeout: 5s
    depends_on:
      broker:
        condition: service_healthy

  elasticsearch:
    image: elasticsearch:7.10.1
    container_name: elasticsearch
    hostname: elasticsearch
    restart: always
    env_file:
      - .env
    environment:
      bootstrap.memory_lock: "true"
      discovery.type: single-node
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      ELASTIC_USERNAME: elastic
      ELASTIC_PASSWORD: ${ES_PASSWORD}
      xpack.security.enabled: "true"
      cluster.name: elasticsearch_cluster
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - elasticsearch_datadir:/usr/share/elasticsearch/data
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 3
      start_period: 20s
      test: curl -sS --fail http://elasticsearch:9200/_cluster/health?wait_for_status=yellow&timeout=0s
      timeout: 5s

  mysql:
    image: mariadb:10.5.8
    container_name: mysql
    hostname: mysql
    restart: always
    env_file:
      - .env
    environment:
      MYSQL_ROOT_HOST: '%'
      MYSQL_USER: datahub
      MYSQL_ROOT_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: datahub
    ports:
      - 3306:3306
    command:
    - --character-set-server=utf8mb4
    - --collation-server=utf8mb4_bin
    - --default-authentication-plugin=mysql_native_password
    volumes:
      - mysql_datadir:/var/lib/mysql
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 5
      start_period: 20s
      test: mysqladmin ping -h mysql -u datahub --password=${MYSQL_PASSWORD}
      timeout: 5s


  # Dependency Setup
  kafka-setup:
    image: acryldata/datahub-kafka-setup:head
    container_name: kafka-setup
    hostname: kafka-setup
    environment:
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      USE_CONFLUENT_SCHEMA_REGISTRY: TRUE
      DATAHUB_PRECREATE_TOPICS: "true"
    networks:
      - demo_network
    labels:
      datahub_setup_job: true
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy

  elasticsearch-setup:
    image: acryldata/datahub-elasticsearch-setup:head
    container_name: elasticsearch-setup
    hostname: elasticsearch-setup
    env_file:
      - .env
    environment:
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: ${ES_PASSWORD}
      ELASTICSEARCH_PROTOCOL: http
      ELASTICSEARCH_USE_SSL: "false"
      USE_AWS_ELASTICSEARCH: "false"
    networks:
      - demo_network
    labels:
      datahub_setup_job: true
    depends_on:
      elasticsearch:
        condition: service_healthy

  mysql-setup:
    image: acryldata/datahub-mysql-setup:head
    container_name: mysql-setup
    hostname: mysql-setup
    env_file:
      - .env
    environment:
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_USERNAME: datahub
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      DATAHUB_DB_NAME: datahub
    networks:
      - demo_network
    labels:
      datahub_setup_job: true
    depends_on:
      mysql:
        condition: service_healthy
  

  # Datahub
  datahub-upgrade:
    image: acryldata/datahub-upgrade:head
    container_name: datahub-upgrade
    hostname: datahub-upgrade
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_SCHEMAREGISTRY_URL: http://schema-registry:8081
      
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: ${ES_PASSWORD}
      ELASTICSEARCH_PROTOCOL: http
      ELASTICSEARCH_USE_SSL: "false"
      USE_AWS_ELASTICSEARCH: "false"
      ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX: "true"
      ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX: "true"
      ELASTICSEARCH_BUILD_INDICES_CLONE_INDICES: false
      GRAPH_SERVICE_IMPL: elasticsearch

      EBEAN_DATASOURCE_DRIVER: com.mysql.jdbc.Driver
      EBEAN_DATASOURCE_HOST: mysql:3306
      EBEAN_DATASOURCE_URL: jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
      EBEAN_DATASOURCE_USERNAME: datahub
      EBEAN_DATASOURCE_PASSWORD: ${MYSQL_PASSWORD}
      
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      ENTITY_REGISTRY_CONFIG_PATH: /datahub/datahub-gms/resources/entity-registry.yml
      BACKFILL_BROWSE_PATHS_V2: "true"
      REPROCESS_DEFAULT_BROWSE_PATHS_V2: "false"
    command:
    - -u
    - SystemUpdate
    networks:
      - demo_network
    depends_on:
      kafka-setup:
        condition: service_completed_successfully
      elasticsearch-setup:
        condition: service_completed_successfully
      mysql-setup:
        condition: service_completed_successfully
    labels:
      datahub_setup_job: true

  datahub-gms:
    image: acryldata/datahub-gms:head
    container_name: datahub-gms
    hostname: datahub-gms
    restart: always
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_SCHEMAREGISTRY_URL: http://schema-registry:8081
      KAFKA_CONSUMER_STOP_ON_DESERIALIZATION_ERROR: "true"
      DATAHUB_UPGRADE_HISTORY_KAFKA_CONSUMER_GROUP_ID: generic-duhe-consumer-job-client-gms
      
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: ${ES_PASSWORD}
      ELASTICSEARCH_PROTOCOL: http
      ELASTICSEARCH_USE_SSL: "false"
      ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX: "true"
      ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX: "true"
      ES_BULK_REFRESH_POLICY: WAIT_UNTIL
      GRAPH_SERVICE_DIFF_MODE_ENABLED: "true"
      GRAPH_SERVICE_IMPL: elasticsearch
      JAVA_OPTS: -Xms1g -Xmx1g
      ENTITY_REGISTRY_CONFIG_PATH: /datahub/datahub-gms/resources/entity-registry.yml
      ENTITY_SERVICE_ENABLE_RETENTION: "true"

      EBEAN_DATASOURCE_DRIVER: com.mysql.jdbc.Driver
      EBEAN_DATASOURCE_HOST: mysql:3306
      EBEAN_DATASOURCE_URL: jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
      EBEAN_DATASOURCE_USERNAME: datahub
      EBEAN_DATASOURCE_PASSWORD: ${MYSQL_PASSWORD}
      
      DATAHUB_SERVER_TYPE: quickstart
      DATAHUB_TELEMETRY_ENABLED: "true"
      MAE_CONSUMER_ENABLED: "true"
      MCE_CONSUMER_ENABLED: "true"
      PE_CONSUMER_ENABLED: "true"
      UI_INGESTION_ENABLED: "true"
    ports:
      - 8080:8080
    # volumes:
    #   - ${PWD}/.datahub/plugins:/etc/datahub/plugins
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 3
      start_period: 90s
      test: curl -sS --fail http://datahub-gms:8080/health
      timeout: 5s
    depends_on:
      datahub-upgrade:
        condition: service_completed_successfully

  datahub-actions:
    image: acryldata/datahub-actions:head
    container_name: datahub-actions
    hostname: datahub-actions
    restart: always
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      METADATA_AUDIT_EVENT_NAME: MetadataAuditEvent_v4
      METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME: MetadataChangeLog_Versioned_v1
      
      DATAHUB_GMS_PROTOCOL: http
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      
      DATAHUB_SYSTEM_CLIENT_ID: __datahub_system
      DATAHUB_SYSTEM_CLIENT_SECRET: ${DATAHUB_SECRET}
    networks:
      - demo_network
    depends_on:
      datahub-gms:
        condition: service_healthy
    
  datahub-frontend-react:
    image: acryldata/datahub-frontend-react:head
    container_name: datahub-frontend-react
    hostname: datahub-frontend-react
    restart: always
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      DATAHUB_TRACKING_TOPIC: DataHubUsageEvent_v1

      ELASTIC_CLIENT_HOST: elasticsearch
      ELASTIC_CLIENT_PORT: 9200
      ELASTIC_CLIENT_USERNAME: elastic
      ELASTIC_CLIENT_PASSWORD: ${ES_PASSWORD}
      ELASTIC_CLIENT_USE_SSL: "false"

      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_SECRET: ${DATAHUB_SECRET}
      DATAHUB_APP_VERSION: 1.0
      DATAHUB_PLAY_MEM_BUFFER_SIZE: 10MB
      JAVA_OPTS: -Xms512m -Xmx512m -Dhttp.port=9002 -Dconfig.file=datahub-frontend/conf/application.conf -Djava.security.auth.login.config=datahub-frontend/conf/jaas.conf -Dlogback.configurationFile=datahub-frontend/conf/logback.xml -Dlogback.debug=false -Dpidfile.path=/dev/null
    ports:
      - 9002:9002
    volumes:
      # - ${PWD}/.datahub/plugins:/etc/datahub/plugins
      - ${PWD}/user.props:/datahub-frontend/conf/user.props
    networks:
      - demo_network
    depends_on:
      postgres:
        condition: service_healthy



  # PostgreSQL Datawarehouse
  postgres:
    image: postgres:14-alpine
    container_name: postgres
    hostname: postgres
    restart: always
    env_file:
      - .env
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRESQL_PASSWORD}
      POSTGRES_DB: postgres
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - 5432:5432
    command:
      - "postgres"
    volumes:
      - pgdata_dir:/var/lib/postgresql/data
      - ${PWD}/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - demo_network
    healthcheck:
      interval: 1s
      retries: 5
      start_period: 20s
      test: ["CMD-SHELL", "sh -c 'pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}'"]
      timeout: 5s

  
  # Data Ingestion
  data-ingestion:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: data-ingestion
    hostname: data-ingestion
    env_file:
      - .env
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USERNAME: postgres
      DB_PASSWORD: ${POSTGRESQL_PASSWORD}
      DB_NAME: postgres
    volumes:
      - ${PWD}/staging:/tmp
    networks:
      - demo_network
    depends_on:
      postgres:
        condition: service_healthy
    

  # Data Transformation
  dbt-deps:
    # For Apple M1
    platform: linux/x86_64
    image: ghcr.io/dbt-labs/dbt-postgres:latest
    container_name: dbt-deps
    hostname: dbt-deps
    command: "deps"
    volumes:
      - ${PWD}/dbt/project:/usr/app
      - ${PWD}/dbt/profiles.yml:/root/.dbt/profiles.yml:ro
    networks:
      - demo_network

  data-transformation:
    # For Apple M1
    platform: linux/x86_64
    image: ghcr.io/dbt-labs/dbt-postgres:latest
    container_name: data-transformation
    hostname: data-transformation
    command: "build"
    volumes:
      - ${PWD}/dbt/project:/usr/app
      - ${PWD}/dbt/profiles.yml:/root/.dbt/profiles.yml:ro
    networks:
      - demo_network
    depends_on:
      postgres:
        condition: service_healthy
      data-ingestion:
        condition: service_completed_successfully
      dbt-deps:
        condition: service_completed_successfully

  data-documentation:
    # For Apple M1
    platform: linux/x86_64
    image: ghcr.io/dbt-labs/dbt-postgres:latest
    container_name: data-documentation
    hostname: data-documentation
    command: "docs generate --no-compile"
    volumes:
      - ${PWD}/dbt/project:/usr/app
      - ${PWD}/dbt/profiles.yml:/root/.dbt/profiles.yml:ro
    networks:
      - demo_network
    depends_on:
      data-transformation:
        condition: service_completed_successfully
  

  # Metadata Ingestion  
  metadata-ingestion-pg:
    image: acryldata/datahub-ingestion:head
    container_name: metadata-ingestion-pg
    hostname: metadata-ingestion-pg
    command: "ingest --config /postgres_recipe.yml"
    volumes: 
      - ${PWD}/postgres_recipe.yml:/postgres_recipe.yml:ro
    networks:
      - demo_network
    depends_on:
      postgres:
        condition: service_healthy
      datahub-gms:
        condition: service_healthy
      data-documentation:
        condition: service_completed_successfully

  metadata-ingestion-dbt:
    image: acryldata/datahub-ingestion:head
    container_name: metadata-ingestion-dbt
    hostname: metadata-ingestion-dbt
    command: "ingest --config /dbt_recipe.yml"
    volumes: 
      - ${PWD}/dbt_recipe.yml:/dbt_recipe.yml:ro
      - ${PWD}/dbt/project/target:/datahub-ingestion/dbt:ro
    networks:
      - demo_network
    depends_on:
      datahub-gms:
        condition: service_healthy
      data-documentation:
        condition: service_completed_successfully
      metadata-ingestion-pg:
        condition: service_completed_successfully
    


networks:
  demo_network:
    driver: bridge

volumes:
  broker_logdir:
  elasticsearch_datadir:
  mysql_datadir:
  pgdata_dir:
